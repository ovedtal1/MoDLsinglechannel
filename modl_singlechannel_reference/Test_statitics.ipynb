{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os, sys\n",
    "import logging\n",
    "import random\n",
    "import h5py\n",
    "import shutil\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import sigpy.plot as pl\n",
    "import torch\n",
    "import sigpy as sp\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib\n",
    "# import custom libraries\n",
    "from utils import transforms as T\n",
    "from utils import subsample as ss\n",
    "from utils import complex_utils as cplx\n",
    "from utils.resnet2p1d import generate_model\n",
    "from utils.flare_utils import roll\n",
    "from utils import data_ut as dut\n",
    "# import custom classes\n",
    "from utils.datasets import SliceData\n",
    "from subsample_fastmri import MaskFunc\n",
    "from MoDL_single import UnrolledModel\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "from models.SAmodel import MyNetwork\n",
    "from models.Unrolled import Unrolled\n",
    "from models.UnrolledRef import UnrolledRef\n",
    "from models.UnrolledTransformer import UnrolledTrans\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "%load_ext autoreload\n",
    "%autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tal/docker/MoDLsinglechannel/modl_singlechannel_reference\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tal/docker/dockvenv/bin/python3\n"
     ]
    }
   ],
   "source": [
    "!which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_file = \"./L2_checkpoints_poisson_x2_SAunrolled/model_80.pt\"\n",
    "checkpoint_file = \"./L2_checkpoints_poisson_x2_SAunrolledRef/model_80.pt\"\n",
    "#checkpoint_file = \"./L2_checkpoints_poisson_x2_MoDL/model_80.pt\"\n",
    "#checkpoint_file = \"./L2_checkpoints_poisson_x2_SAunrolledRef/model_20.pt\"\n",
    "checkpoint = torch.load(checkpoint_file,map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = checkpoint[\"params\"]\n",
    "#single_MoDL = UnrolledModel(params).to(device)\n",
    "#single_MoDL = MyNetwork(2,2).to(device)\n",
    "#single_MoDL = Unrolled(params).to(device)\n",
    "single_MoDL = UnrolledRef(params).to(device)\n",
    "#single_MoDL = UnrolledTrans(params).to(device)\n",
    "single_MoDL.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    Data Transformer for training unrolled reconstruction models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask_func, args, use_seed=False):\n",
    "        self.mask_func = mask_func\n",
    "        self.use_seed = use_seed\n",
    "        self.rng = np.random.RandomState()\n",
    "\n",
    "    def __call__(self, kspace, target, reference_kspace,reference,slice):\n",
    "        im_lowres = abs(sp.ifft(sp.resize(sp.resize(kspace,(256,24)),(256,160))))\n",
    "        magnitude_vals = im_lowres.reshape(-1)\n",
    "        k = int(round(0.05 * magnitude_vals.shape[0]))\n",
    "        scale = magnitude_vals[magnitude_vals.argsort()[::-1][k]]\n",
    "        kspace = kspace/scale\n",
    "        target = target/scale\n",
    "        # Convert everything from numpy arrays to tensors\n",
    "        kspace_torch = cplx.to_tensor(kspace).float()   \n",
    "        target_torch = cplx.to_tensor(target).float()   \n",
    "        # Use poisson mask instead\n",
    "        mask2 = sp.mri.poisson((256,160), 5, calib=(18, 14), dtype=float, crop_corner=False, return_density=True, seed=0, max_attempts=6, tol=0.01)\n",
    "        mask2[128-10:128+9,80-8:80+7] = 1\n",
    "        mask_torch = torch.stack([torch.tensor(mask2).float(),torch.tensor(mask2).float()],dim=2)\n",
    "        mask_torch = T.kspace_crop(mask_torch,0.67)\n",
    "        #kspace_torch = T.kspace_cut(mask_torch,0.5)\n",
    "        kspace_torch = T.awgn_torch(kspace_torch,15,L=1)\n",
    "        kspace_torch = kspace_torch*mask_torch\n",
    "\n",
    "        ### Reference addition ###\n",
    "        im_lowres_ref = abs(sp.ifft(sp.resize(sp.resize(reference_kspace,(256,24)),(256,160))))\n",
    "        magnitude_vals_ref = im_lowres_ref.reshape(-1)\n",
    "        k_ref = int(round(0.05 * magnitude_vals_ref.shape[0]))\n",
    "        scale_ref = magnitude_vals_ref[magnitude_vals_ref.argsort()[::-1][k_ref]]\n",
    "        reference = reference / scale_ref\n",
    "        reference_torch = cplx.to_tensor(reference).float()\n",
    "\n",
    "        return kspace_torch,target_torch,mask_torch, reference_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(args):\n",
    "    # Generate k-t undersampling masks\n",
    "    train_mask = MaskFunc([0.08],[4])\n",
    "    train_data = SliceData(\n",
    "        root=str(args.data_path),\n",
    "        transform=DataTransform(train_mask, args),\n",
    "        sample_rate=1\n",
    "    )\n",
    "    return train_data\n",
    "def create_data_loaders(args):\n",
    "    train_data = create_datasets(args)\n",
    "#     print(train_data[0])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader\n",
    "def build_optim(args, params):\n",
    "    optimizer = torch.optim.Adam(params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tal/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 5, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE input: 0.004426472599056894\n",
      "Average MSE output: 0.0014809640124440193\n",
      "Average PSNR input: 23.604061656064967\n",
      "Average PSNR output: 28.54786727302269\n",
      "Average SSIM input: 0.3855\n",
      "Average SSIM output: 0.5526\n",
      "Test slices: 56\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio as psnr, normalized_root_mse as nrmse\n",
    "from skimage import img_as_float\n",
    "from types import SimpleNamespace as Namespace\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "params = Namespace()\n",
    "params.data_path = \"./test_data/patient29b\"\n",
    "params.batch_size = 1\n",
    "params.num_grad_steps = 4\n",
    "params.num_cg_steps = 8\n",
    "params.share_weights = True\n",
    "params.modl_lamda = 0.05\n",
    "params.lr = 0.00001\n",
    "params.weight_decay = 0\n",
    "params.lr_step_size = 10\n",
    "params.lr_gamma = 0.5\n",
    "params.epoch = 21\n",
    "params.reference_mode = 0\n",
    "params.reference_lambda = 0.1\n",
    "\n",
    "# Load test data\n",
    "test_loader = create_data_loaders(params)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "mse_in_list, mse_out_list = [], []\n",
    "psnr_in_list, psnr_out_list = [], []\n",
    "ssim_in_list, ssim_out_list = [], []\n",
    "\n",
    "single_MoDL.eval()  # Set model to evaluation mode\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    for data in test_loader:\n",
    "        input, target, mask, reference = data\n",
    "        input = input.to(device)\n",
    "        reference = reference.to(device)\n",
    "        mask = mask.to(device)\n",
    "        # Forward pass through the model\n",
    "        output = single_MoDL(input.float(),reference_image=reference, mask=mask)\n",
    "        \n",
    "        # Handle output\n",
    "        kspace_out = T.fft2(output.cpu().squeeze(0))\n",
    "        kspace_out = T.kspace_crop(kspace_out.squeeze(0),0.67)\n",
    "        im_out = T.ifft2(kspace_out)\n",
    "        \n",
    "        kspace_target = T.fft2(target.cpu().squeeze(0))\n",
    "        kspace_target = T.kspace_crop(kspace_target.squeeze(0),0.67)\n",
    "        target = T.ifft2(kspace_target)\n",
    "\n",
    "        \n",
    "        #print(cplx.to_numpy(im_out.cpu()).shape)\n",
    "        cplx_image_target = cplx.to_numpy(target.cpu())\n",
    "        cplx_image_in = cplx.to_numpy(T.ifft2(input.cpu())).squeeze(0)\n",
    "        cplx_image_out = cplx.to_numpy(im_out.cpu().squeeze(0))\n",
    "        cplx_image_reference = cplx.to_numpy(reference.cpu()).squeeze(0)\n",
    "    \n",
    "\n",
    "        target_numpy = cplx.to_numpy(target.cpu())\n",
    "        input_numpy = cplx.to_numpy(T.ifft2(input.cpu())).squeeze(0)\n",
    "        out_numpy = cplx.to_numpy(output.cpu()).squeeze(0)\n",
    "\n",
    "        target_numpy_norm = np.abs(target_numpy)/np.max(np.abs(target_numpy)).squeeze(0)\n",
    "        input_numpy_norm = np.abs(input_numpy)/np.max(np.abs(input_numpy)).squeeze(0)\n",
    "        out_numpy_norm = np.abs(out_numpy)/np.max(np.abs(out_numpy)).squeeze(0)\n",
    "\n",
    "        \"\"\"\n",
    "        # Find comparison area:\n",
    "        area = target_numpy_norm > 0.10\n",
    "        kernel = np.ones((5, 5)) / 25.0\n",
    "        area = convolve(area.squeeze(0), kernel, mode='constant', cval=0.0)\n",
    "        area[area>0.1] = 1\n",
    "        target_numpy_norm = target_numpy_norm * area\n",
    "        input_numpy_norm = input_numpy_norm * area\n",
    "        out_numpy_norm = out_numpy_norm * area\n",
    "        \"\"\"\n",
    "        # Calculate metrics\n",
    "        # Calculate SSIM values\n",
    "        data_range = target_numpy_norm.max() - target_numpy_norm.min()\n",
    "\n",
    "        ssim_in, _ = ssim(target_numpy_norm, input_numpy_norm, data_range=data_range, full=True)\n",
    "        ssim_out, _ = ssim(target_numpy_norm, out_numpy_norm, data_range=data_range, full=True)\n",
    "\n",
    "\n",
    "        # Calculate PSNR\n",
    "        psnr_in = T.PSNR_numpy(target_numpy_norm, input_numpy_norm)\n",
    "        psnr_out = T.PSNR_numpy(target_numpy_norm, out_numpy_norm)\n",
    "\n",
    "        #print(img_in.shape)\n",
    "        #print(img_out.shape)\n",
    "        #print(img_target.shape)\n",
    "        \"\"\"\n",
    "        plt_concat = np.concatenate((np.abs(cplx_image_reference),np.abs(cplx_image_in),np.abs(cplx_image_out),np.abs(cplx_image_target)),axis=1)\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(20, 5))  # 1 row, 3 columns\n",
    "        im = axs.imshow(plt_concat, cmap='gray')\n",
    "        axs.set_title(f'Reference                 Input (PSNR: {psnr_in:.2f})               Output (PSNR: {psnr_out:.2f})               Target')\n",
    "        \n",
    "\n",
    "        plt_concat = np.concatenate((np.abs( cplx.to_numpy(input.cpu()).squeeze(0)),np.abs(cplx.to_numpy(kspace_out)),np.abs(cplx.to_numpy(kspace_target))),axis=1)\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(20, 5))  # 1 row, 3 columns\n",
    "        im = axs.imshow(np.log(plt_concat), cmap='gray')\n",
    "        axs.set_title(f'Input (PSNR: {psnr_in:.2f})               Output (PSNR: {psnr_out:.2f})               Target')\n",
    "        \"\"\"   \n",
    "        # Calculate MSE\n",
    "        mse_in = np.mean(np.abs(input_numpy_norm-target_numpy_norm)**2)\n",
    "        mse_out = np.mean(np.abs(out_numpy_norm-target_numpy_norm)**2)\n",
    "\n",
    "        # Append metrics to lists\n",
    "        mse_in_list.append(mse_in)\n",
    "        mse_out_list.append(mse_out)\n",
    "        psnr_in_list.append(psnr_in)\n",
    "        psnr_out_list.append(psnr_out)\n",
    "        ssim_in_list.append(ssim_in)\n",
    "        ssim_out_list.append(ssim_out)\n",
    "\n",
    "\n",
    "# Calculate and print average metrics\n",
    "print(f'Average MSE input: {np.mean(mse_in_list)}')\n",
    "print(f'Average MSE output: {np.mean(mse_out_list)}')\n",
    "print(f'Average PSNR input: {np.mean(psnr_in_list)}')\n",
    "print(f'Average PSNR output: {np.mean(psnr_out_list)}')\n",
    "print(f'Average SSIM input: {np.mean(ssim_in_list):.4f}')\n",
    "print(f'Average SSIM output: {np.mean(ssim_out_list):.4f}')\n",
    "\n",
    "print(f'Test slices: {len(test_loader)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
