{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os, sys\n",
    "import logging\n",
    "import random\n",
    "import h5py\n",
    "import shutil\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import sigpy.plot as pl\n",
    "import torch\n",
    "import sigpy as sp\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib\n",
    "# import custom libraries\n",
    "from utils import transforms as T\n",
    "from utils import subsample as ss\n",
    "from utils import complex_utils as cplx\n",
    "from utils.resnet2p1d import generate_model\n",
    "from utils.flare_utils import roll\n",
    "# import custom classes\n",
    "from utils.datasets import SliceData\n",
    "from subsample_fastmri import MaskFunc\n",
    "from MoDL_single import UnrolledModel\n",
    "import argparse\n",
    "from models.SAmodel import MyNetwork\n",
    "from models.Unrolled import Unrolled\n",
    "from models.UnrolledRef import UnrolledRef\n",
    "from models.UnrolledTransformer import UnrolledTrans\n",
    "import matplotlib.pyplot as plt\n",
    "from ImageFusionBlock import ImageFusionBlock\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "%load_ext autoreload\n",
    "%autoreload 0\n",
    "from ImageFusion_Dualbranch_Fusion.densefuse_net import DenseFuseNet\n",
    "from ImageFusion_Dualbranch_Fusion.channel_fusion import channel_f as channel_fusion\n",
    "import itertools\n",
    "from RCAN import CombinedNetwork\n",
    "from models.FusionNet import FusionNet\n",
    "from recon_net_wrap import ViTfuser\n",
    "from UnrolledViT import UnrolledViT\n",
    "\n",
    "from fastmri.data import transforms, subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    Data Transformer for training unrolled reconstruction models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask_func, args, use_seed=False):\n",
    "        self.mask_func = mask_func\n",
    "        self.use_seed = use_seed\n",
    "        self.rng = np.random.RandomState()\n",
    "    def get_mask_func(self, factor):\n",
    "        center_fractions = 0.08 * 4/factor # RandomMaskFunc\n",
    "        mask_func = subsample.EquiSpacedMaskFunc(\n",
    "        center_fractions=[center_fractions],\n",
    "        accelerations=[factor], \n",
    "        )\n",
    "        return mask_func\n",
    "    \n",
    "    def __call__(self, kspace, target, reference_kspace, reference,slice):\n",
    "        im_lowres = abs(sp.ifft(sp.resize(sp.resize(kspace,(256,24)),(256,160))))\n",
    "        magnitude_vals = im_lowres.reshape(-1)\n",
    "        k = int(round(0.05 * magnitude_vals.shape[0]))\n",
    "        scale = magnitude_vals[magnitude_vals.argsort()[::-1][k]]\n",
    "        kspace = kspace/scale\n",
    "        target = target/scale\n",
    "        # Convert everything from numpy arrays to tensors\n",
    "        kspace_torch = cplx.to_tensor(kspace).float()   \n",
    "        target_torch = cplx.to_tensor(target).float()  \n",
    "        target_torch = T.ifft2(T.kspace_cut(T.fft2(target_torch),0.67,0.67)) \n",
    "        # Use poisson mask instead\n",
    "        #mask2 = sp.mri.poisson((256,160), 5, calib=(18, 14), dtype=float, crop_corner=False, return_density=True, seed=0, max_attempts=6, tol=0.01)\n",
    "        #mask2[128-10:128+9,80-8:80+7] = 1\n",
    "        #mask_torch = torch.stack([torch.tensor(mask2).float(),torch.tensor(mask2).float()],dim=2)\n",
    "        #mask_torch = T.kspace_crop(mask_torch,0.67)\n",
    "        #kspace_torch = T.kspace_cut(mask_torch,0.5)\n",
    "        kspace_torch = T.awgn_torch(kspace_torch,5,L=1)\n",
    "        ## Masking\n",
    "        mask_func = self.get_mask_func(3)\n",
    "        kspace_torch = T.kspace_cut(kspace_torch,0.67,0.67)\n",
    "        kspace_torch = transforms.apply_mask(kspace_torch, mask_func)[0]\n",
    "        # kspace_torch = kspace_torch*mask_torch # For poisson\n",
    "        \n",
    "        mask = np.abs(cplx.to_numpy(kspace_torch))!=0\n",
    "        mask_torch = torch.stack([torch.tensor(mask).float(),torch.tensor(mask).float()],dim=2)\n",
    "        \n",
    "        ### Reference addition ###\n",
    "        im_lowres_ref = abs(sp.ifft(sp.resize(sp.resize(reference_kspace,(256,24)),(256,160))))\n",
    "        magnitude_vals_ref = im_lowres_ref.reshape(-1)\n",
    "        k_ref = int(round(0.05 * magnitude_vals_ref.shape[0]))\n",
    "        scale_ref = magnitude_vals_ref[magnitude_vals_ref.argsort()[::-1][k_ref]]\n",
    "        reference = reference / scale_ref\n",
    "        reference_torch = cplx.to_tensor(reference).float()\n",
    "        reference_torch_kspace = T.fft2(reference_torch)\n",
    "        reference_torch_kspace = T.kspace_cut(reference_torch_kspace,0.67,0.67)\n",
    "        reference_torch = T.ifft2(reference_torch_kspace)\n",
    "        \n",
    "\n",
    "        return kspace_torch,target_torch,mask_torch, reference_torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(args):\n",
    "    # Generate k-t undersampling masks\n",
    "    train_mask = MaskFunc([0.08],[4])\n",
    "    train_data = SliceData(\n",
    "        root=str(args.data_path),\n",
    "        transform=DataTransform(train_mask, args),\n",
    "        sample_rate=1\n",
    "    )\n",
    "    return train_data\n",
    "def create_data_loaders(args):\n",
    "    train_data = create_datasets(args)\n",
    "#     print(train_data[0])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader\n",
    "def build_optim(args, params):\n",
    "    optimizer = torch.optim.Adam(params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameters\n",
    "params = Namespace()\n",
    "#params.data_path = \"./registered_data/patient23b/\"\n",
    "params.data_path = \"./registered_data/\"\n",
    "params.batch_size = 4\n",
    "params.num_grad_steps = 1 #4\n",
    "params.num_cg_steps = 8 #8\n",
    "params.share_weights = True\n",
    "params.modl_lamda = 0.05\n",
    "params.lr = 0.0005 #0.0005\n",
    "#params.lr = 0.0001\n",
    "params.weight_decay = 0\n",
    "params.lr_step_size = 6\n",
    "params.lr_gamma = 0.3\n",
    "params.epoch = 31\n",
    "params.reference_mode = 1\n",
    "params.reference_lambda = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tal/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 5, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_loader = create_data_loaders(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared weights\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "pretrained_model = DenseFuseNet().to(device)\n",
    "checkpoint = torch.load('./ImageFusion_Dualbranch_Fusion/weights/best.pkl')\n",
    "pretrained_model.load_state_dict(checkpoint['weight'])\n",
    "\n",
    "## Set the FusionNet\n",
    "FusionNet = FusionNet().to(device)\n",
    "FusionNet.encoder1.load_state_dict(pretrained_model.encoder.state_dict())\n",
    "FusionNet.encoder2.load_state_dict(pretrained_model.encoder.state_dict())\n",
    "FusionNet.decoder.load_state_dict(pretrained_model.decoder.state_dict())\n",
    "\n",
    "## Don't train Encoder & Decoder\n",
    "FusionNet.encoder1.requires_grad_(False)\n",
    "FusionNet.encoder2.requires_grad_(False)\n",
    "FusionNet.decoder.requires_grad_(False)\n",
    "\n",
    "fuser = CombinedNetwork().to(device)\n",
    "\n",
    "from torchvision.models import vgg16\n",
    "vgg16_model = vgg16(pretrained=True).to(device)#.requires_grad_(False)\n",
    "vgg16_model.classifier = vgg16_model.classifier[:-1]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from vision_transformer import VisionTransformer\n",
    "net = VisionTransformer(\n",
    "  avrg_img_size=320,\n",
    "  patch_size = (10,10),\n",
    "  in_chans=1,\n",
    "  embed_dim=64,\n",
    "  depth=10,\n",
    "  num_heads=16\n",
    "\n",
    ")\n",
    "\n",
    "from recon_net import ReconNet\n",
    "model = UnrolledViT(params).to(device)\n",
    "model2 = ReconNet(net).to(device)#.requires_grad_(False)\n",
    "cp = torch.load('./lsdir-2x+hq50k_vit_epoch_60.pt', map_location=device)\n",
    "model2.load_state_dict(cp['model_state_dict'])\n",
    "\n",
    "\"\"\"\n",
    "model.requires_grad_(False)\n",
    "\n",
    "for net in model.similaritynets:\n",
    "    net.param1.requires_grad_(True)\n",
    "    net.param2.requires_grad_(True)\n",
    "    #net.recon_net.net.head.requires_grad_(True)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer, \n",
    "    max_lr=0.0001,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=params.epoch,\n",
    "    pct_start=0.01,\n",
    "    anneal_strategy='linear',\n",
    "    cycle_momentum=False,\n",
    "    base_momentum=0., \n",
    "    max_momentum=0.,\n",
    "    div_factor = 25.,\n",
    "    final_div_factor=1.,\n",
    ")\n",
    "\"\"\"\n",
    "optimizer = build_optim(params,  model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, params.lr_step_size, params.lr_gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  0/ 31] Iter = [   0/ 134] Loss = 0.6987 Avg Loss = 0.6987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Learning rate: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  1/ 31] Iter = [   0/ 134] Loss = 0.1395 Avg Loss = 0.1395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Learning rate: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  2/ 31] Iter = [   0/ 134] Loss = 0.1209 Avg Loss = 0.1209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Learning rate: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  3/ 31] Iter = [   0/ 134] Loss = 0.1239 Avg Loss = 0.1239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Learning rate: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  4/ 31] Iter = [   0/ 134] Loss = 0.1086 Avg Loss = 0.1086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Learning rate: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  5/ 31] Iter = [   0/ 134] Loss = 0.1074 Avg Loss = 0.1074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Learning rate: 0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  6/ 31] Iter = [   0/ 134] Loss = 0.1006 Avg Loss = 0.1006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Learning rate: 0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  7/ 31] Iter = [   0/ 134] Loss = 0.09372 Avg Loss = 0.09372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Learning rate: 0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  8/ 31] Iter = [   0/ 134] Loss = 0.1042 Avg Loss = 0.1042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Learning rate: 0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  9/ 31] Iter = [   0/ 134] Loss = 0.09177 Avg Loss = 0.09177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Learning rate: 0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 10/ 31] Iter = [   0/ 134] Loss = 0.09243 Avg Loss = 0.09243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Learning rate: 0.00015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 11/ 31] Iter = [   0/ 134] Loss = 0.08573 Avg Loss = 0.08573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Learning rate: 4.4999999999999996e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 12/ 31] Iter = [   0/ 134] Loss = 0.09567 Avg Loss = 0.09567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Learning rate: 4.4999999999999996e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 13/ 31] Iter = [   0/ 134] Loss = 0.08598 Avg Loss = 0.08598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Learning rate: 4.4999999999999996e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 14/ 31] Iter = [   0/ 134] Loss = 0.1187 Avg Loss = 0.1187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Learning rate: 4.4999999999999996e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 15/ 31] Iter = [   0/ 134] Loss = 0.07376 Avg Loss = 0.07376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Learning rate: 4.4999999999999996e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 16/ 31] Iter = [   0/ 134] Loss = 0.1053 Avg Loss = 0.1053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Learning rate: 4.4999999999999996e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 17/ 31] Iter = [   0/ 134] Loss = 0.09685 Avg Loss = 0.09685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Learning rate: 1.3499999999999998e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 18/ 31] Iter = [   0/ 134] Loss = 0.07685 Avg Loss = 0.07685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Learning rate: 1.3499999999999998e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 19/ 31] Iter = [   0/ 134] Loss = 0.08422 Avg Loss = 0.08422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Learning rate: 1.3499999999999998e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 20/ 31] Iter = [   0/ 134] Loss = 0.08148 Avg Loss = 0.08148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Learning rate: 1.3499999999999998e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 21/ 31] Iter = [   0/ 134] Loss = 0.08072 Avg Loss = 0.08072\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 98\u001b[0m\n\u001b[1;32m     96\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     97\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 98\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.99\u001b[39m \u001b[38;5;241m*\u001b[39m avg_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.01\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    100\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch = [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIter = [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28miter\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m4d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m4d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4g\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Avg Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4g\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    104\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Load for fine-tunning\n",
    "\"\"\"\n",
    "checkpoint_file = \"./L2_checkpoints_poisson_x2_FusionNet/model_30.pt\"\n",
    "checkpoint = torch.load(checkpoint_file,map_location=device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.recon_net.requires_grad_(True)\n",
    "\"\"\"\n",
    "from fastmri.losses import SSIMLoss\n",
    "criterion = SSIMLoss().to(device)\n",
    "#criterionMSE = nn.MSELoss()\n",
    "#criterion = nn.L1Loss()\n",
    "\n",
    "epochs_plot = []\n",
    "losses_plot = []\n",
    "\n",
    "for epoch in range(params.epoch):\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    running_loss = 0.0\n",
    "    for iter, data in enumerate(train_loader):\n",
    "        input,target,mask,reference = data\n",
    "        input = input.to(device).float()\n",
    "        target = target.to(device).float()\n",
    "        mask = mask.to(device)\n",
    "        reference = reference.to(device).float()\n",
    "        image = T.ifft2(input)\n",
    "        image = image.permute(0,3,1,2)\n",
    "\n",
    "        #print(f'image shape: {image.shape}')\n",
    "        #print(f'reference shape: {reference.shape}')\n",
    "\n",
    "        target_image = target.permute(0,3,1,2) \n",
    "        #print(f'ref size: {reference_image.shape}')\n",
    "        real_part_tar = target_image[:,0,:,:].unsqueeze(1)\n",
    "        imag_part_tar = target_image[:,1,:,:].unsqueeze(1)\n",
    "        mag_tar = torch.sqrt(real_part_tar**2 + imag_part_tar**2)\n",
    "        \"\"\"\n",
    "        in_pad, wpad, hpad = model2.pad(mag_tar)\n",
    "        input_norm,mean,std = model2.norm(in_pad.float())\n",
    "        # Feature extract\n",
    "        #print(mag_tar.shape)\n",
    "        mag_tar = torch.cat((mag_tar,mag_tar,mag_tar),dim =1).to(device)\n",
    "        \n",
    "        features_target = vgg16_model(torch.cat((mag_tar,mag_tar,mag_tar),dim =1).to(device)).data\n",
    "        \"\"\"\n",
    "        #print(f'Features target: {features_target.shape}')\n",
    "        im_out = model(input,reference)#.squeeze(3)\n",
    "\n",
    "        \"\"\"\n",
    "        # Plot the concatenated image\n",
    "        real_part = image[0,0,:,:]\n",
    "        imag_part = image[0,1,:,:]\n",
    "        mag_image = torch.sqrt(real_part**2 + imag_part**2)\n",
    "        real_part_ref = reference[0,:,:,0]\n",
    "        imag_part_ref = reference[0,:,:,1]\n",
    "        mag_ref = torch.sqrt(real_part_ref**2 + imag_part_ref**2)\n",
    "        mag_ref = mag_ref.cpu().detach().numpy()\n",
    "        print(f'Mag ref: {mag_ref.shape}')\n",
    "        import matplotlib.pyplot as plt\n",
    "        %matplotlib inline\n",
    "        print(im_out.shape)\n",
    "        print(mag_tar.shape)\n",
    "        im_out = im_out.cpu().detach().numpy().squeeze(0)\n",
    "        concat = np.concatenate((mag_ref,mag_image.cpu().detach().numpy(),np.abs(im_out),mag_tar.squeeze(0).cpu().detach().numpy()),axis=1)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.imshow(concat, cmap='gray')\n",
    "        plt.title('reference                         in                           out                       target   ')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        l = torch(mag_tar)\n",
    "        \"\"\"\n",
    "        #loss = criterion(im_out,features_target)\n",
    "        # SSIM\n",
    "        maxval = torch.max(torch.cat((im_out,mag_tar.permute(0,2,3,1)),dim=1))\n",
    "        im_out = im_out.permute(0,3,1,2)\n",
    "\n",
    "        #features_out = vgg16_model(torch.cat((im_out,im_out,im_out),dim =1))\n",
    "        \n",
    "        #print(features_out.shape)\n",
    "        data_range = torch.tensor([maxval], device=device).view(1, 1, 1, 1).expand(im_out.size(0), im_out.size(1), im_out.size(2)-6, im_out.size(3)-6)\n",
    "        #print(mag_tar.shape)\n",
    "        #print(im_out.shape)\n",
    "        #print(data_range.shape)\n",
    "        # SSIM\n",
    "        loss = criterion(im_out, mag_tar.to(device), data_range.to(device)) \n",
    "        #loss = criterionMSE(features_out, features_target)\n",
    "        \n",
    "        # L1\n",
    "        #loss = criterion(features_out, features_out)\n",
    "        # MSE\n",
    "        #loss = criterion(im_out,mag_tar.permute(0,2,3,1))\n",
    "\n",
    "        running_loss = running_loss + loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        avg_loss = 0.99 * avg_loss + 0.01 * loss.item() if iter > 0 else loss.item()\n",
    "        if iter % 400 == 0:\n",
    "            logging.info(\n",
    "                f'Epoch = [{epoch:3d}/{params.epoch:3d}] '\n",
    "                f'Iter = [{iter:4d}/{len(train_loader):4d}] '\n",
    "                f'Loss = {loss.item():.4g} Avg Loss = {avg_loss:.4g}'\n",
    "            )\n",
    "    #Saving the model\n",
    "    exp_dir = \"L2_checkpoints_poisson_x2_ViT_LR/\"\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'params': params,\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'exp_dir': exp_dir\n",
    "            },\n",
    "            f=os.path.join(exp_dir, 'model_%d.pt'%(epoch))\n",
    "    )\n",
    "    running_loss = running_loss / len(train_loader)\n",
    "    #scheduler.step(running_loss)\n",
    "    scheduler.step()\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    print(f'Epoch {epoch+1}, Learning rate: {current_lr}')\n",
    "\n",
    "    #print(f'Epoch {epoch+1}, Learning rate: {scheduler.get_last_lr()[0]}')\n",
    "    # Append epoch and average loss to plot lists\n",
    "    epochs_plot.append(epoch)\n",
    "    losses_plot.append(running_loss)\n",
    "\n",
    "# Plotting the loss curve\n",
    "plt.figure()\n",
    "plt.plot(epochs_plot, losses_plot, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('SA unrolled with Reference L2 train Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(exp_dir, 'loss_plot_plato_down.png'))  # Save plot as an image\n",
    "\n",
    "# Save all_losses to a file for later comparison\n",
    "losses_file = os.path.join(exp_dir, 'all_losses.txt')\n",
    "with open(losses_file, 'w') as f:\n",
    "    for loss in losses_plot:\n",
    "        f.write(f'{loss}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
