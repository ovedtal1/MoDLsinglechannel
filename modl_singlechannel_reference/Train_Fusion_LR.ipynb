{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os, sys\n",
    "import logging\n",
    "import random\n",
    "import h5py\n",
    "import shutil\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import sigpy.plot as pl\n",
    "import torch\n",
    "import sigpy as sp\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib\n",
    "# import custom libraries\n",
    "from utils import transforms as T\n",
    "from utils import subsample as ss\n",
    "from utils import complex_utils as cplx\n",
    "from utils.resnet2p1d import generate_model\n",
    "from utils.flare_utils import roll\n",
    "# import custom classes\n",
    "from utils.datasets import SliceData\n",
    "from subsample_fastmri import MaskFunc\n",
    "from MoDL_single import UnrolledModel\n",
    "import argparse\n",
    "from models.SAmodel import MyNetwork\n",
    "from models.Unrolled import Unrolled\n",
    "from models.UnrolledRef import UnrolledRef\n",
    "from models.UnrolledTransformer import UnrolledTrans\n",
    "import matplotlib.pyplot as plt\n",
    "from ImageFusionBlock import ImageFusionBlock\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "%load_ext autoreload\n",
    "%autoreload 0\n",
    "from ImageFusion_Dualbranch_Fusion.densefuse_net import DenseFuseNet\n",
    "from ImageFusion_Dualbranch_Fusion.channel_fusion import channel_f as channel_fusion\n",
    "import itertools\n",
    "from RCAN import CombinedNetwork\n",
    "from models.FusionNet import FusionNet\n",
    "from recon_net_wrap import ViTfuser\n",
    "#from UnrolledViT import UnrolledViT\n",
    "from UnrolledViTcomplex import UnrolledViT\n",
    "\n",
    "from fastmri.data import transforms, subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    Data Transformer for training unrolled reconstruction models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask_func, args, use_seed=False):\n",
    "        self.mask_func = mask_func\n",
    "        self.use_seed = use_seed\n",
    "        self.rng = np.random.RandomState()\n",
    "    def get_mask_func(self, factor):\n",
    "        center_fractions = 0.08 * 4/factor# RandomMaskFuncEquiSpacedMaskFunc\n",
    "        mask_func = subsample.EquiSpacedMaskFunc(\n",
    "        center_fractions=[center_fractions],\n",
    "        accelerations=[factor], \n",
    "        )\n",
    "        return mask_func\n",
    "    \n",
    "    def __call__(self, kspace, target, reference_kspace, reference,slice):\n",
    "        im_lowres = abs(sp.ifft(sp.resize(sp.resize(kspace,(256,24)),(256,160))))\n",
    "        magnitude_vals = im_lowres.reshape(-1)\n",
    "        k = int(round(0.05 * magnitude_vals.shape[0]))\n",
    "        scale = magnitude_vals[magnitude_vals.argsort()[::-1][k]]\n",
    "        kspace = kspace/scale\n",
    "        target = target/scale\n",
    "        # Convert everything from numpy arrays to tensors\n",
    "        kspace_torch = cplx.to_tensor(kspace).float()   \n",
    "        target_torch = cplx.to_tensor(target).float()  \n",
    "        target_torch = T.ifft2(T.kspace_cut(T.fft2(target_torch),0.67,0.67)) \n",
    "        # Use poisson mask instead\n",
    "        #mask2 = sp.mri.poisson((256,160), 5, calib=(18, 14), dtype=float, crop_corner=False, return_density=True, seed=0, max_attempts=6, tol=0.01)\n",
    "        #mask2[128-10:128+9,80-8:80+7] = 1\n",
    "        #mask_torch = torch.stack([torch.tensor(mask2).float(),torch.tensor(mask2).float()],dim=2)\n",
    "        #mask_torch = T.kspace_crop(mask_torch,0.67)\n",
    "        #kspace_torch = T.kspace_cut(mask_torch,0.5)\n",
    "        kspace_torch = T.awgn_torch(kspace_torch,10,L=1) # 10dB for simulations\n",
    "        ## Masking\n",
    "        mask_func = self.get_mask_func(3)\n",
    "        kspace_torch = T.kspace_cut(kspace_torch,0.67,0.67)\n",
    "        kspace_torch = transforms.apply_mask(kspace_torch, mask_func)[0]\n",
    "        # kspace_torch = kspace_torch*mask_torch # For poisson\n",
    "        \n",
    "        mask = np.abs(cplx.to_numpy(kspace_torch))!=0\n",
    "        mask_torch = torch.stack([torch.tensor(mask).float(),torch.tensor(mask).float()],dim=2)\n",
    "        \n",
    "        ### Reference addition ###\n",
    "        im_lowres_ref = abs(sp.ifft(sp.resize(sp.resize(reference_kspace,(256,24)),(256,160))))\n",
    "        magnitude_vals_ref = im_lowres_ref.reshape(-1)\n",
    "        k_ref = int(round(0.05 * magnitude_vals_ref.shape[0]))\n",
    "        scale_ref = magnitude_vals_ref[magnitude_vals_ref.argsort()[::-1][k_ref]]\n",
    "        reference = reference / scale_ref\n",
    "        reference_torch = cplx.to_tensor(reference).float()\n",
    "        reference_torch_kspace = T.fft2(reference_torch)\n",
    "        reference_torch_kspace = T.kspace_cut(reference_torch_kspace,0.67,0.67)\n",
    "        reference_torch = T.ifft2(reference_torch_kspace)\n",
    "        \n",
    "\n",
    "        return kspace_torch,target_torch,mask_torch, reference_torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(args):\n",
    "    # Generate k-t undersampling masks\n",
    "    train_mask = MaskFunc([0.08],[4])\n",
    "    train_data = SliceData(\n",
    "        root=str(args.data_path),\n",
    "        transform=DataTransform(train_mask, args),\n",
    "        sample_rate=1\n",
    "    )\n",
    "    return train_data\n",
    "def create_data_loaders(args):\n",
    "    train_data = create_datasets(args)\n",
    "#     print(train_data[0])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader\n",
    "def build_optim(args, params):\n",
    "    optimizer = torch.optim.Adam(params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameters\n",
    "params = Namespace()\n",
    "#params.data_path = \"./registered_data/patient23b/\"\n",
    "params.data_path = \"./registered_data/\"\n",
    "params.batch_size = 2 #4\n",
    "params.num_grad_steps = 1 #4\n",
    "params.num_cg_steps = 8 #8\n",
    "params.share_weights = True\n",
    "params.modl_lamda = 0.05\n",
    "params.lr = 0.0001 #0.0005 # used to be 0.0001\n",
    "#params.lr = 0.0001\n",
    "params.weight_decay = 0\n",
    "params.lr_step_size = 5\n",
    "params.lr_gamma = 0.3\n",
    "params.epoch = 61\n",
    "params.reference_mode = 1\n",
    "params.reference_lambda = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tal/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 5, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_loader = create_data_loaders(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tal/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tal/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\noptimizer = optim.Adam(model.parameters(), lr=0.0)\\nscheduler = optim.lr_scheduler.OneCycleLR(\\n    optimizer=optimizer, \\n    max_lr=0.0002,\\n    steps_per_epoch=len(train_loader),\\n    epochs=60,\\n    pct_start=0.01,\\n    anneal_strategy='linear',\\n    cycle_momentum=False,\\n    base_momentum=0., \\n    max_momentum=0.,\\n    div_factor = 25.,\\n    final_div_factor=1.,\\n)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "#model_ft = models.resnet18(weights='DEFAULT').to(device).requires_grad_(False)\n",
    "#model_ft.fc = nn.Identity()\n",
    "#model_ft = models.vgg16(weights='DEFAULT').to(device)#.requires_grad_(False)\n",
    "from FSloss_wrap import VGGLoss,ResNet18Backbone,FeatureEmbedding,contrastive_loss,VGGPerceptualLoss\n",
    "#VGGloss = VGGLoss().to(device)\n",
    "VGGloss = VGGPerceptualLoss().to(device)\n",
    "#UFLoss = ResNet18Backbone().to(device)\n",
    "#UFLoss = VGGLoss().to(device)\n",
    "#UFLoss = models.vgg16(pretrained=True).features[:8+1].to(device)\n",
    "#UFLoss.eval()\n",
    "\n",
    "def extract_patches(images, patch_size=(20, 20), stride=(20, 20)):\n",
    "    # images: Tensor of shape (batch_size, 1, 180, 110)\n",
    "    patches = images.unfold(2, patch_size[0], stride[0]).unfold(3, patch_size[1], stride[1])\n",
    "    patches = patches.permute(0, 2, 3, 1, 4, 5).contiguous()\n",
    "    patches = patches.view(images.size(0), -1, 1, patch_size[0], patch_size[1])\n",
    "    return patches  # Returns patches of shape (batch_size, num_patches, 1, patch_size[0], patch_size[1])\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "patch_size = (20, 20)\n",
    "stride = (20, 20)  # Non-overlapping patches\n",
    "def feature_space_loss(features1, features2):\n",
    "    return F.mse_loss(features1, features2)\n",
    "def pad_image(images):\n",
    "    # images: Tensor of shape (batch_size, 1, 172, 108)\n",
    "    padded_images = F.pad(images, (6, 6, 4, 4), mode='constant', value=0)\n",
    "    return padded_images  # Shape will be (batch_size, 1, 180, 120)\n",
    "#modelLoss = ResNet18Backbone().to(device)\n",
    "#embedding_model = FeatureEmbedding(modelLoss).to(device)\n",
    "#memory_bank = torch.randn(16, 128)  # Assuming num_patches is the number of different patches stored.\n",
    "#memory_bank = nn.functional.normalize(memory_bank, p=2, dim=1)  # Normalize the memory bank vectors\n",
    "\n",
    "\n",
    "from vision_transformer import VisionTransformer\n",
    "net = VisionTransformer(\n",
    "  avrg_img_size=320,\n",
    "  patch_size = (10,10),\n",
    "  in_chans=1,\n",
    "  embed_dim=64,\n",
    "  depth=10,\n",
    "  num_heads=16\n",
    "\n",
    ")\n",
    "\n",
    "from recon_net import ReconNet\n",
    "model = UnrolledViT(params).to(device)\n",
    "#model2 = ReconNet(net).to(device)#.requires_grad_(False)\n",
    "#cp = torch.load('./lsdir-2x+hq50k_vit_epoch_60.pt', map_location=device)\n",
    "#model2.load_state_dict(cp['model_state_dict'])\n",
    "\n",
    "\"\"\"\n",
    "model.requires_grad_(False)\n",
    "\n",
    "for net in model.similaritynets:\n",
    "    net.param1.requires_grad_(True)\n",
    "    net.param2.requires_grad_(True)\n",
    "    #net.recon_net.net.head.requires_grad_(True)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer, \n",
    "    max_lr=0.0001,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=params.epoch,\n",
    "    pct_start=0.01,\n",
    "    anneal_strategy='linear',\n",
    "    cycle_momentum=False,\n",
    "    base_momentum=0., \n",
    "    max_momentum=0.,\n",
    "    div_factor = 25.,\n",
    "    final_div_factor=1.,\n",
    ")\n",
    "\"\"\"\n",
    "# fine tune training\n",
    "\n",
    "optimizer = build_optim(params,  model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, params.lr_step_size, params.lr_gamma)\n",
    "\n",
    "## For ViT only training\n",
    "\"\"\"\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer, \n",
    "    max_lr=0.0002,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=60,\n",
    "    pct_start=0.01,\n",
    "    anneal_strategy='linear',\n",
    "    cycle_momentum=False,\n",
    "    base_momentum=0., \n",
    "    max_momentum=0.,\n",
    "    div_factor = 25.,\n",
    "    final_div_factor=1.,\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  0/ 61] Iter = [   0/ 267] Loss = 2.03 Avg Loss = 2.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  1/ 61] Iter = [   0/ 267] Loss = 1.517 Avg Loss = 1.517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  2/ 61] Iter = [   0/ 267] Loss = 1.197 Avg Loss = 1.197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  3/ 61] Iter = [   0/ 267] Loss = 0.966 Avg Loss = 0.966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Learning rate: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  4/ 61] Iter = [   0/ 267] Loss = 1.092 Avg Loss = 1.092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Learning rate: 3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  5/ 61] Iter = [   0/ 267] Loss = 1.147 Avg Loss = 1.147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Learning rate: 3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  6/ 61] Iter = [   0/ 267] Loss = 0.878 Avg Loss = 0.878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Learning rate: 3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  7/ 61] Iter = [   0/ 267] Loss = 0.7534 Avg Loss = 0.7534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Learning rate: 3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  8/ 61] Iter = [   0/ 267] Loss = 0.8195 Avg Loss = 0.8195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Learning rate: 3e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  9/ 61] Iter = [   0/ 267] Loss = 0.7262 Avg Loss = 0.7262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Learning rate: 9e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 10/ 61] Iter = [   0/ 267] Loss = 0.7777 Avg Loss = 0.7777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Learning rate: 9e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 11/ 61] Iter = [   0/ 267] Loss = 0.6842 Avg Loss = 0.6842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Learning rate: 9e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 12/ 61] Iter = [   0/ 267] Loss = 0.6495 Avg Loss = 0.6495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Learning rate: 9e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 13/ 61] Iter = [   0/ 267] Loss = 0.6902 Avg Loss = 0.6902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Learning rate: 9e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 14/ 61] Iter = [   0/ 267] Loss = 0.7174 Avg Loss = 0.7174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Learning rate: 2.7e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 15/ 61] Iter = [   0/ 267] Loss = 0.5847 Avg Loss = 0.5847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Learning rate: 2.7e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 16/ 61] Iter = [   0/ 267] Loss = 0.6583 Avg Loss = 0.6583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Learning rate: 2.7e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 17/ 61] Iter = [   0/ 267] Loss = 0.6502 Avg Loss = 0.6502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Learning rate: 2.7e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 18/ 61] Iter = [   0/ 267] Loss = 0.8005 Avg Loss = 0.8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Learning rate: 2.7e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 19/ 61] Iter = [   0/ 267] Loss = 0.7162 Avg Loss = 0.7162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Learning rate: 8.1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 20/ 61] Iter = [   0/ 267] Loss = 0.7471 Avg Loss = 0.7471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Learning rate: 8.1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 21/ 61] Iter = [   0/ 267] Loss = 0.7104 Avg Loss = 0.7104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Learning rate: 8.1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 22/ 61] Iter = [   0/ 267] Loss = 0.6302 Avg Loss = 0.6302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Learning rate: 8.1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 23/ 61] Iter = [   0/ 267] Loss = 0.6245 Avg Loss = 0.6245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Learning rate: 8.1e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 24/ 61] Iter = [   0/ 267] Loss = 0.6763 Avg Loss = 0.6763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Learning rate: 2.43e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 25/ 61] Iter = [   0/ 267] Loss = 0.7871 Avg Loss = 0.7871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Learning rate: 2.43e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 26/ 61] Iter = [   0/ 267] Loss = 0.6419 Avg Loss = 0.6419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Learning rate: 2.43e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 27/ 61] Iter = [   0/ 267] Loss = 0.6406 Avg Loss = 0.6406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Learning rate: 2.43e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 28/ 61] Iter = [   0/ 267] Loss = 0.6038 Avg Loss = 0.6038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Learning rate: 2.43e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 29/ 61] Iter = [   0/ 267] Loss = 0.6482 Avg Loss = 0.6482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Learning rate: 7.29e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 30/ 61] Iter = [   0/ 267] Loss = 0.6413 Avg Loss = 0.6413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Learning rate: 7.29e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 31/ 61] Iter = [   0/ 267] Loss = 0.7117 Avg Loss = 0.7117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Learning rate: 7.29e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 32/ 61] Iter = [   0/ 267] Loss = 0.7182 Avg Loss = 0.7182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Learning rate: 7.29e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 33/ 61] Iter = [   0/ 267] Loss = 0.6319 Avg Loss = 0.6319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Learning rate: 7.29e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 34/ 61] Iter = [   0/ 267] Loss = 0.6567 Avg Loss = 0.6567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Learning rate: 2.187e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 35/ 61] Iter = [   0/ 267] Loss = 0.6356 Avg Loss = 0.6356\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "### Load for fine-tunning\n",
    "\"\"\"\n",
    "checkpoint_file = \"./L2_checkpoints_myTrain/model_5.pt\"\n",
    "checkpoint = torch.load(checkpoint_file,map_location=device)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\"\"\"\n",
    "\n",
    "from fastmri.losses import SSIMLoss\n",
    "criterion = SSIMLoss().to(device)\n",
    "criterionMSE = nn.MSELoss()\n",
    "#criterion = nn.L1Loss()\n",
    "\n",
    "epochs_plot = []\n",
    "losses_plot = []\n",
    "\n",
    "for epoch in range(params.epoch):\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "    running_loss = 0.0\n",
    "    for iter, data in enumerate(train_loader):\n",
    "        input,target,mask,reference = data\n",
    "        input = input.to(device).float()\n",
    "        target = target.to(device).float()\n",
    "        mask = mask.to(device)\n",
    "        reference = reference.to(device).float()\n",
    "        image = T.ifft2(input)\n",
    "        image = image.permute(0,3,1,2)\n",
    "\n",
    "        #print(f'image shape: {image.shape}')\n",
    "        #print(f'reference shape: {reference.shape}')\n",
    "\n",
    "        target_image = target.permute(0,3,1,2) \n",
    "        #print(f'ref size: {reference_image.shape}')\n",
    "        real_part_tar = target_image[:,0,:,:].unsqueeze(1)\n",
    "        imag_part_tar = target_image[:,1,:,:].unsqueeze(1)\n",
    "        mag_tar = torch.sqrt(real_part_tar**2 + imag_part_tar**2).to(device)\n",
    "        \"\"\"\n",
    "        in_pad, wpad, hpad = model2.pad(mag_tar)\n",
    "        input_norm,mean,std = model2.norm(in_pad.float())\n",
    "        # Feature extract\n",
    "        #print(mag_tar.shape)\n",
    "        mag_tar = torch.cat((mag_tar,mag_tar,mag_tar),dim =1).to(device)\n",
    "        \n",
    "        features_target = vgg16_model(torch.cat((mag_tar,mag_tar,mag_tar),dim =1).to(device)).data\n",
    "        \"\"\"\n",
    "        #print(f'Features target: {features_target.shape}')\n",
    "        im_out = model(input,reference)#.squeeze(3)\n",
    "\n",
    "        \"\"\"\n",
    "        # Plot the concatenated image\n",
    "        real_part = image[0,0,:,:]\n",
    "        imag_part = image[0,1,:,:]\n",
    "        mag_image = torch.sqrt(real_part**2 + imag_part**2)\n",
    "        real_part_ref = reference[0,:,:,0]\n",
    "        imag_part_ref = reference[0,:,:,1]\n",
    "        mag_ref = torch.sqrt(real_part_ref**2 + imag_part_ref**2)\n",
    "        mag_ref = mag_ref.cpu().detach().numpy()\n",
    "        print(f'Mag ref: {mag_ref.shape}')\n",
    "        import matplotlib.pyplot as plt\n",
    "        %matplotlib inline\n",
    "        print(im_out.shape)\n",
    "        print(mag_tar.shape)\n",
    "        im_out = im_out.cpu().detach().numpy().squeeze(0)\n",
    "        concat = np.concatenate((mag_ref,mag_image.cpu().detach().numpy(),np.abs(im_out),mag_tar.squeeze(0).cpu().detach().numpy()),axis=1)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.imshow(concat, cmap='gray')\n",
    "        plt.title('reference                         in                           out                       target   ')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        l = torch(mag_tar)\n",
    "        \"\"\"\n",
    "        #loss = criterion(im_out,features_target)\n",
    "        # SSIM\n",
    "        maxval = torch.max(torch.cat((im_out,mag_tar.permute(0,2,3,1)),dim=1))\n",
    "        im_out = im_out.permute(0,3,1,2)\n",
    "\n",
    "        #features_out = vgg16_model(torch.cat((im_out,im_out,im_out),dim =1))\n",
    "        \n",
    "        #print(features_out.shape)\n",
    "        data_range = torch.tensor([maxval], device=device).view(1, 1, 1, 1).expand(im_out.size(0), im_out.size(1), im_out.size(2)-6, im_out.size(3)-6)\n",
    "        #print(mag_tar.shape)\n",
    "        #print(im_out.shape)\n",
    "        #print(data_range.shape)\n",
    "        # SSIM\n",
    "        #loss = criterion(im_out, mag_tar.to(device), data_range.to(device))\n",
    "        # pad:\n",
    "        im_out_pad = torch.cat((im_out,im_out,im_out),dim =1)/maxval\n",
    "        mag_tar_pad = torch.cat((mag_tar,mag_tar,mag_tar),dim =1)/maxval\n",
    "        #loss = nn.MSELoss()(model_ft.features(im_out_pad), model_ft.features(mag_tar_pad))\n",
    "        \n",
    "        # SSIM + style - ready loss\n",
    "        #print(f'ssim is : {+ criterion(im_out, mag_tar.to(device), data_range.to(device))}')\n",
    "        loss = VGGloss(im_out,mag_tar.to(device)) + criterion(im_out, mag_tar.to(device), data_range.to(device))  # For tests2\n",
    "        \n",
    "        # SSIM loss for grant\n",
    "        #loss = criterion(im_out, mag_tar.to(device), data_range.to(device))\n",
    "        #loss = criterionMSE(im_out,mag_tar.to(device))\n",
    "        \"\"\"\n",
    "        padded_out = pad_image(im_out)\n",
    "        padded_target = pad_image(mag_tar)\n",
    "        #print(f'padded out size: {padded_out.shape}')\n",
    "        out_patches = extract_patches(padded_out, patch_size, stride)\n",
    "        target_patches = extract_patches(padded_target, patch_size, stride)\n",
    "        #print(f'out_patches size: {out_patches.shape}')\n",
    "        loss = 0\n",
    "        loss_tmp = 0\n",
    "        # Forward pass for each patch\n",
    "        for i in range(out_patches.size(1)):\n",
    "            image_patch = out_patches[:, i]  # Shape: (batch_size, 1, 20, 20)\n",
    "            target_patch = target_patches[:, i]  # Shape: (batch_size, 1, 20, 20)\n",
    "            \n",
    "            #Tripple to use in resnet:\n",
    "            #image_patch = torch.cat((image_patch,image_patch,image_patch),dim=1)\n",
    "            #target_patch = torch.cat((target_patch,target_patch,target_patch),dim=1)\n",
    "            #print(f'image patch: {image_patch.shape}')\n",
    "            # Compute feature space loss\n",
    "\n",
    "            #features = UFLoss(image_patch,target_patch)\n",
    "            #target_features = UFLoss(target_patch)\n",
    "        \n",
    "            loss_tmp += VGGloss(image_patch,target_patch.to(device))  #divide beacuse of channels\n",
    "        loss = loss_tmp/(170*100) + criterion(im_out, mag_tar.to(device), data_range.to(device))\n",
    "        \"\"\"\n",
    "        # L1\n",
    "        #loss = criterion(features_out, features_out)\n",
    "        # MSE\n",
    "        #loss = criterion(im_out,mag_tar.permute(0,2,3,1))\n",
    "        \n",
    "        running_loss = running_loss + loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss = 0.99 * avg_loss + 0.01 * loss.item() if iter > 0 else loss.item()\n",
    "        if iter % 400 == 0:\n",
    "            logging.info(\n",
    "                f'Epoch = [{epoch:3d}/{params.epoch:3d}] '\n",
    "                f'Iter = [{iter:4d}/{len(train_loader):4d}] '\n",
    "                f'Loss = {loss.item():.4g} Avg Loss = {avg_loss:.4g}'\n",
    "            )\n",
    "    #Saving the model\n",
    "    exp_dir = \"L2_checkpoints_myTrain/\"\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'params': params,\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'exp_dir': exp_dir\n",
    "            },\n",
    "            f=os.path.join(exp_dir, 'model_%d.pt'%(epoch))\n",
    "    )\n",
    "    running_loss = running_loss / len(train_loader)\n",
    "    #scheduler.step(running_loss)\n",
    "    scheduler.step()\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    print(f'Epoch {epoch+1}, Learning rate: {current_lr}')\n",
    "\n",
    "    #print(f'Epoch {epoch+1}, Learning rate: {scheduler.get_last_lr()[0]}')\n",
    "    # Append epoch and average loss to plot lists\n",
    "    epochs_plot.append(epoch)\n",
    "    losses_plot.append(running_loss)\n",
    "\n",
    "# Plotting the loss curve\n",
    "plt.figure()\n",
    "plt.plot(epochs_plot, losses_plot, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('SA unrolled with Reference L2 train Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(exp_dir, 'loss_plot_plato_down.png'))  # Save plot as an image\n",
    "\n",
    "# Save all_losses to a file for later comparison\n",
    "losses_file = os.path.join(exp_dir, 'all_losses.txt')\n",
    "with open(losses_file, 'w') as f:\n",
    "    for loss in losses_plot:\n",
    "        f.write(f'{loss}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
