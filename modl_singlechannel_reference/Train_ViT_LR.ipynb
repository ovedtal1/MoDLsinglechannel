{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os, sys\n",
    "import logging\n",
    "import random\n",
    "import h5py\n",
    "import shutil\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import sigpy.plot as pl\n",
    "import torch\n",
    "import sigpy as sp\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib\n",
    "# import custom libraries\n",
    "from utils import transforms as T\n",
    "from utils import subsample as ss\n",
    "from utils import complex_utils as cplx\n",
    "from utils.resnet2p1d import generate_model\n",
    "from utils.flare_utils import roll\n",
    "# import custom classes\n",
    "from utils.datasets import SliceData\n",
    "from subsample_fastmri import MaskFunc\n",
    "from MoDL_single import UnrolledModel\n",
    "import argparse\n",
    "from models.SAmodel import MyNetwork\n",
    "from models.Unrolled import Unrolled\n",
    "from models.UnrolledRef import UnrolledRef\n",
    "from models.UnrolledTransformer import UnrolledTrans\n",
    "import matplotlib.pyplot as plt\n",
    "from ImageFusionBlock import ImageFusionBlock\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "%load_ext autoreload\n",
    "%autoreload 0\n",
    "from ImageFusion_Dualbranch_Fusion.densefuse_net import DenseFuseNet\n",
    "from ImageFusion_Dualbranch_Fusion.channel_fusion import channel_f as channel_fusion\n",
    "import itertools\n",
    "from RCAN import CombinedNetwork\n",
    "from models.FusionNet import FusionNet\n",
    "from recon_net_wrap import ViTfuser\n",
    "#from UnrolledViT import UnrolledViT\n",
    "from UnrolledViTcomplex import UnrolledViT\n",
    "\n",
    "from fastmri.data import transforms, subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    Data Transformer for training unrolled reconstruction models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask_func, args, use_seed=False):\n",
    "        self.mask_func = mask_func\n",
    "        self.use_seed = use_seed\n",
    "        self.rng = np.random.RandomState()\n",
    "    def get_mask_func(self, factor):\n",
    "        center_fractions = 0.08 * 4/factor# RandomMaskFuncEquiSpacedMaskFunc\n",
    "        mask_func = subsample.EquiSpacedMaskFunc(\n",
    "        center_fractions=[center_fractions],\n",
    "        accelerations=[factor], \n",
    "        )\n",
    "        return mask_func\n",
    "    \n",
    "    def __call__(self, kspace, target, reference_kspace, reference,slice):\n",
    "        im_lowres = abs(sp.ifft(sp.resize(sp.resize(kspace,(256,24)),(256,160))))\n",
    "        magnitude_vals = im_lowres.reshape(-1)\n",
    "        k = int(round(0.05 * magnitude_vals.shape[0]))\n",
    "        scale = magnitude_vals[magnitude_vals.argsort()[::-1][k]]\n",
    "        kspace = kspace/scale\n",
    "        target = target/scale\n",
    "        # Convert everything from numpy arrays to tensors\n",
    "        kspace_torch = cplx.to_tensor(kspace).float()   \n",
    "        target_torch = cplx.to_tensor(target).float()  \n",
    "        target_torch = T.ifft2(T.kspace_cut(T.fft2(target_torch),0.67,0.67)) \n",
    "        kspace_torch = T.awgn_torch(kspace_torch,30,L=1) # 10dB for simulations\n",
    "        ## Masking\n",
    "        mask_func = self.get_mask_func(3)\n",
    "        kspace_torch = T.kspace_cut(kspace_torch,0.67,0.67)\n",
    "        kspace_torch = transforms.apply_mask(kspace_torch, mask_func)[0]\n",
    "        # kspace_torch = kspace_torch*mask_torch # For poisson\n",
    "        \n",
    "        mask = np.abs(cplx.to_numpy(kspace_torch))!=0\n",
    "        mask_torch = torch.stack([torch.tensor(mask).float(),torch.tensor(mask).float()],dim=2)\n",
    "        \n",
    "        ### Reference addition ###\n",
    "        im_lowres_ref = abs(sp.ifft(sp.resize(sp.resize(reference_kspace,(256,24)),(256,160))))\n",
    "        magnitude_vals_ref = im_lowres_ref.reshape(-1)\n",
    "        k_ref = int(round(0.05 * magnitude_vals_ref.shape[0]))\n",
    "        scale_ref = magnitude_vals_ref[magnitude_vals_ref.argsort()[::-1][k_ref]]\n",
    "        reference = reference / scale_ref\n",
    "        reference_torch = cplx.to_tensor(reference).float()\n",
    "        reference_torch_kspace = T.fft2(reference_torch)\n",
    "        reference_torch_kspace = T.kspace_cut(reference_torch_kspace,0.67,0.67)\n",
    "        reference_torch = T.ifft2(reference_torch_kspace)\n",
    "        \n",
    "\n",
    "        return kspace_torch,target_torch,mask_torch, reference_torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(args):\n",
    "    # Generate k-t undersampling masks\n",
    "    train_mask = MaskFunc([0.08],[4])\n",
    "    train_data = SliceData(\n",
    "        root=str(args.data_path),\n",
    "        transform=DataTransform(train_mask, args),\n",
    "        sample_rate=1\n",
    "    )\n",
    "    return train_data\n",
    "def create_data_loaders(args):\n",
    "    train_data = create_datasets(args)\n",
    "#     print(train_data[0])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader\n",
    "def build_optim(args, params):\n",
    "    optimizer = torch.optim.Adam(params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameters\n",
    "params = Namespace()\n",
    "#params.data_path = \"./registered_data/patient23b/\"\n",
    "params.data_path = \"./registered_data/\"\n",
    "params.batch_size = 4 #4\n",
    "params.num_grad_steps = 1 #4\n",
    "params.num_cg_steps = 8 #8\n",
    "params.share_weights = True\n",
    "params.modl_lamda = 0.05\n",
    "params.lr = 0.0001 #0.0005 # used to be 0.0001\n",
    "#params.lr = 0.0001\n",
    "params.weight_decay = 0\n",
    "params.lr_step_size = 5\n",
    "params.lr_gamma = 0.3\n",
    "params.epoch = 1001\n",
    "params.reference_mode = 1\n",
    "params.reference_lambda = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tal/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 5, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_loader = create_data_loaders(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tal/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tal/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "#model_ft = models.resnet18(weights='DEFAULT').to(device).requires_grad_(False)\n",
    "#model_ft.fc = nn.Identity()\n",
    "#model_ft = models.vgg16(weights='DEFAULT').to(device)#.requires_grad_(False)\n",
    "from FSloss_wrap import VGGLoss,ResNet18Backbone,FeatureEmbedding,contrastive_loss,VGGPerceptualLoss\n",
    "#VGGloss = VGGLoss().to(device)\n",
    "VGGloss = VGGPerceptualLoss().to(device)\n",
    "#UFLoss = ResNet18Backbone().to(device)\n",
    "#UFLoss = VGGLoss().to(device)\n",
    "#UFLoss = models.vgg16(pretrained=True).features[:8+1].to(device)\n",
    "#UFLoss.eval()\n",
    "\n",
    "def extract_patches(images, patch_size=(20, 20), stride=(20, 20)):\n",
    "    # images: Tensor of shape (batch_size, 1, 180, 110)\n",
    "    patches = images.unfold(2, patch_size[0], stride[0]).unfold(3, patch_size[1], stride[1])\n",
    "    patches = patches.permute(0, 2, 3, 1, 4, 5).contiguous()\n",
    "    patches = patches.view(images.size(0), -1, 1, patch_size[0], patch_size[1])\n",
    "    return patches  # Returns patches of shape (batch_size, num_patches, 1, patch_size[0], patch_size[1])\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "patch_size = (20, 20)\n",
    "stride = (20, 20)  # Non-overlapping patches\n",
    "def feature_space_loss(features1, features2):\n",
    "    return F.mse_loss(features1, features2)\n",
    "def pad_image(images):\n",
    "    # images: Tensor of shape (batch_size, 1, 172, 108)\n",
    "    padded_images = F.pad(images, (6, 6, 4, 4), mode='constant', value=0)\n",
    "    return padded_images  # Shape will be (batch_size, 1, 180, 120)\n",
    "#modelLoss = ResNet18Backbone().to(device)\n",
    "#embedding_model = FeatureEmbedding(modelLoss).to(device)\n",
    "#memory_bank = torch.randn(16, 128)  # Assuming num_patches is the number of different patches stored.\n",
    "#memory_bank = nn.functional.normalize(memory_bank, p=2, dim=1)  # Normalize the memory bank vectors\n",
    "\n",
    "\n",
    "from vision_transformer import VisionTransformer\n",
    "from recon_net import ReconNet\n",
    "net = VisionTransformer(\n",
    "    avrg_img_size=320,\n",
    "    patch_size=(10,10),\n",
    "    in_chans=1, embed_dim=64, \n",
    "    depth=10, num_heads=16,\n",
    "    )\n",
    "model = ReconNet(net).to(device)\n",
    "\n",
    "#model2 = ReconNet(net).to(device)#.requires_grad_(False)\n",
    "#cp = torch.load('./lsdir-2x+hq50k_vit_epoch_60.pt', map_location=device)\n",
    "#model2.load_state_dict(cp['model_state_dict'])\n",
    "\n",
    "\"\"\"\n",
    "model.requires_grad_(False)\n",
    "\n",
    "for net in model.similaritynets:\n",
    "    net.param1.requires_grad_(True)\n",
    "    net.param2.requires_grad_(True)\n",
    "    #net.recon_net.net.head.requires_grad_(True)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer, \n",
    "    max_lr=0.0001,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=params.epoch,\n",
    "    pct_start=0.01,\n",
    "    anneal_strategy='linear',\n",
    "    cycle_momentum=False,\n",
    "    base_momentum=0., \n",
    "    max_momentum=0.,\n",
    "    div_factor = 25.,\n",
    "    final_div_factor=1.,\n",
    ")\n",
    "\"\"\"\n",
    "# fine tune training\n",
    "\"\"\"\n",
    "optimizer = build_optim(params,  model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, params.lr_step_size, params.lr_gamma)\n",
    "\"\"\"\n",
    "## For ViT only training\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer, \n",
    "    max_lr=0.0002,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=1000,\n",
    "    pct_start=0.01,\n",
    "    anneal_strategy='linear',\n",
    "    cycle_momentum=False,\n",
    "    base_momentum=0., \n",
    "    max_momentum=0.,\n",
    "    div_factor = 25.,\n",
    "    final_div_factor=1.,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  0/1001] Iter = [   0/ 134] Loss = 0.03742 Avg Loss = 0.03742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Learning rate: 8.14339058999253e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  1/1001] Iter = [   0/ 134] Loss = 0.03955 Avg Loss = 0.03955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Learning rate: 8.286781179985063e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  2/1001] Iter = [   0/ 134] Loss = 0.03961 Avg Loss = 0.03961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Learning rate: 8.430171769977594e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  3/1001] Iter = [   0/ 134] Loss = 0.04284 Avg Loss = 0.04284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Learning rate: 8.573562359970127e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  4/1001] Iter = [   0/ 134] Loss = 0.0337 Avg Loss = 0.0337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Learning rate: 8.716952949962658e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  5/1001] Iter = [   0/ 134] Loss = 0.03799 Avg Loss = 0.03799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Learning rate: 8.86034353995519e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  6/1001] Iter = [   0/ 134] Loss = 0.04287 Avg Loss = 0.04287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Learning rate: 9.003734129947722e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  7/1001] Iter = [   0/ 134] Loss = 0.036 Avg Loss = 0.036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Learning rate: 9.147124719940253e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  8/1001] Iter = [   0/ 134] Loss = 0.03607 Avg Loss = 0.03607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Learning rate: 9.290515309932785e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  9/1001] Iter = [   0/ 134] Loss = 0.03004 Avg Loss = 0.03004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Learning rate: 9.433905899925316e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 10/1001] Iter = [   0/ 134] Loss = 0.03448 Avg Loss = 0.03448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Learning rate: 9.57729648991785e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 11/1001] Iter = [   0/ 134] Loss = 0.03278 Avg Loss = 0.03278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Learning rate: 9.72068707991038e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 12/1001] Iter = [   0/ 134] Loss = 0.03023 Avg Loss = 0.03023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Learning rate: 9.864077669902911e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 13/1001] Iter = [   0/ 134] Loss = 0.0374 Avg Loss = 0.0374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Learning rate: 1.0007468259895444e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 14/1001] Iter = [   0/ 134] Loss = 0.03565 Avg Loss = 0.03565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Learning rate: 1.0150858849887977e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 15/1001] Iter = [   0/ 134] Loss = 0.0399 Avg Loss = 0.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Learning rate: 1.0294249439880508e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 16/1001] Iter = [   0/ 134] Loss = 0.02739 Avg Loss = 0.02739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Learning rate: 1.0437640029873039e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 17/1001] Iter = [   0/ 134] Loss = 0.03525 Avg Loss = 0.03525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Learning rate: 1.0581030619865571e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 18/1001] Iter = [   0/ 134] Loss = 0.03671 Avg Loss = 0.03671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Learning rate: 1.0724421209858102e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 19/1001] Iter = [   0/ 134] Loss = 0.03462 Avg Loss = 0.03462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Learning rate: 1.0867811799850635e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 20/1001] Iter = [   0/ 134] Loss = 0.03586 Avg Loss = 0.03586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Learning rate: 1.1011202389843166e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 21/1001] Iter = [   0/ 134] Loss = 0.02698 Avg Loss = 0.02698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Learning rate: 1.1154592979835699e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 22/1001] Iter = [   0/ 134] Loss = 0.03536 Avg Loss = 0.03536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Learning rate: 1.129798356982823e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 23/1001] Iter = [   0/ 134] Loss = 0.02891 Avg Loss = 0.02891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Learning rate: 1.1441374159820762e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 24/1001] Iter = [   0/ 134] Loss = 0.03609 Avg Loss = 0.03609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Learning rate: 1.1584764749813293e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 25/1001] Iter = [   0/ 134] Loss = 0.03533 Avg Loss = 0.03533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Learning rate: 1.1728155339805824e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 26/1001] Iter = [   0/ 134] Loss = 0.0332 Avg Loss = 0.0332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Learning rate: 1.1871545929798357e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 27/1001] Iter = [   0/ 134] Loss = 0.02441 Avg Loss = 0.02441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Learning rate: 1.2014936519790888e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 28/1001] Iter = [   0/ 134] Loss = 0.0345 Avg Loss = 0.0345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Learning rate: 1.2158327109783421e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 29/1001] Iter = [   0/ 134] Loss = 0.02825 Avg Loss = 0.02825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Learning rate: 1.2301717699775952e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 30/1001] Iter = [   0/ 134] Loss = 0.0339 Avg Loss = 0.0339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Learning rate: 1.2445108289768483e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 31/1001] Iter = [   0/ 134] Loss = 0.02503 Avg Loss = 0.02503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Learning rate: 1.2588498879761016e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 32/1001] Iter = [   0/ 134] Loss = 0.0323 Avg Loss = 0.0323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Learning rate: 1.2731889469753548e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 33/1001] Iter = [   0/ 134] Loss = 0.03783 Avg Loss = 0.03783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Learning rate: 1.287528005974608e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 34/1001] Iter = [   0/ 134] Loss = 0.03343 Avg Loss = 0.03343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Learning rate: 1.301867064973861e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 35/1001] Iter = [   0/ 134] Loss = 0.02736 Avg Loss = 0.02736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Learning rate: 1.3162061239731141e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 36/1001] Iter = [   0/ 134] Loss = 0.03195 Avg Loss = 0.03195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Learning rate: 1.3305451829723674e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 37/1001] Iter = [   0/ 134] Loss = 0.02711 Avg Loss = 0.02711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Learning rate: 1.3448842419716207e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 38/1001] Iter = [   0/ 134] Loss = 0.03391 Avg Loss = 0.03391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Learning rate: 1.3592233009708738e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 39/1001] Iter = [   0/ 134] Loss = 0.03106 Avg Loss = 0.03106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Learning rate: 1.3735623599701269e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 40/1001] Iter = [   0/ 134] Loss = 0.03418 Avg Loss = 0.03418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Learning rate: 1.3879014189693801e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 41/1001] Iter = [   0/ 134] Loss = 0.03641 Avg Loss = 0.03641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Learning rate: 1.4022404779686334e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 42/1001] Iter = [   0/ 134] Loss = 0.0316 Avg Loss = 0.0316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Learning rate: 1.4165795369678865e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 43/1001] Iter = [   0/ 134] Loss = 0.03725 Avg Loss = 0.03725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Learning rate: 1.4309185959671396e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 44/1001] Iter = [   0/ 134] Loss = 0.03189 Avg Loss = 0.03189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Learning rate: 1.4452576549663927e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 45/1001] Iter = [   0/ 134] Loss = 0.0273 Avg Loss = 0.0273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Learning rate: 1.459596713965646e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 46/1001] Iter = [   0/ 134] Loss = 0.03934 Avg Loss = 0.03934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Learning rate: 1.4739357729648993e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 47/1001] Iter = [   0/ 134] Loss = 0.03445 Avg Loss = 0.03445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Learning rate: 1.4882748319641524e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 48/1001] Iter = [   0/ 134] Loss = 0.03523 Avg Loss = 0.03523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Learning rate: 1.5026138909634055e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 49/1001] Iter = [   0/ 134] Loss = 0.03548 Avg Loss = 0.03548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Learning rate: 1.5169529499626586e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 50/1001] Iter = [   0/ 134] Loss = 0.03372 Avg Loss = 0.03372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51, Learning rate: 1.5312920089619117e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 51/1001] Iter = [   0/ 134] Loss = 0.03699 Avg Loss = 0.03699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52, Learning rate: 1.545631067961165e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 52/1001] Iter = [   0/ 134] Loss = 0.03397 Avg Loss = 0.03397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53, Learning rate: 1.5599701269604182e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 53/1001] Iter = [   0/ 134] Loss = 0.03871 Avg Loss = 0.03871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54, Learning rate: 1.5743091859596713e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 54/1001] Iter = [   0/ 134] Loss = 0.03266 Avg Loss = 0.03266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55, Learning rate: 1.5886482449589247e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 55/1001] Iter = [   0/ 134] Loss = 0.037 Avg Loss = 0.037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56, Learning rate: 1.6029873039581775e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 56/1001] Iter = [   0/ 134] Loss = 0.04151 Avg Loss = 0.04151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57, Learning rate: 1.617326362957431e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 57/1001] Iter = [   0/ 134] Loss = 0.03328 Avg Loss = 0.03328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58, Learning rate: 1.631665421956684e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 58/1001] Iter = [   0/ 134] Loss = 0.0323 Avg Loss = 0.0323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Learning rate: 1.646004480955937e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 59/1001] Iter = [   0/ 134] Loss = 0.04018 Avg Loss = 0.04018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Learning rate: 1.6603435399551906e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [ 60/1001] Iter = [   0/ 134] Loss = 0.02946 Avg Loss = 0.02946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
  