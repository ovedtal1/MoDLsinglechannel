{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os, sys\n",
    "import logging\n",
    "import random\n",
    "import h5py\n",
    "import shutil\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import sigpy.plot as pl\n",
    "import torch\n",
    "import sigpy as sp\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib\n",
    "# import custom libraries\n",
    "from utils import transforms as T\n",
    "from utils import subsample as ss\n",
    "from utils import complex_utils as cplx\n",
    "from utils.resnet2p1d import generate_model\n",
    "from utils.flare_utils import roll\n",
    "# import custom classes\n",
    "from utils.datasets import SliceData\n",
    "from subsample_fastmri import MaskFunc\n",
    "from MoDL_single import UnrolledModel\n",
    "import argparse\n",
    "from models.SAmodel import MyNetwork\n",
    "from models.Unrolled import Unrolled\n",
    "from models.UnrolledRef import UnrolledRef\n",
    "from models.UnrolledTransformer import UnrolledTrans\n",
    "import matplotlib.pyplot as plt\n",
    "from ImageFusionBlock import ImageFusionBlock\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "%load_ext autoreload\n",
    "%autoreload 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "    \"\"\"\n",
    "    Data Transformer for training unrolled reconstruction models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mask_func, args, use_seed=False):\n",
    "        self.mask_func = mask_func\n",
    "        self.use_seed = use_seed\n",
    "        self.rng = np.random.RandomState()\n",
    "\n",
    "    def __call__(self, kspace, target, reference, reference_kspace,slice):\n",
    "        im_lowres = abs(sp.ifft(sp.resize(sp.resize(kspace,(256,24)),(256,160))))\n",
    "        magnitude_vals = im_lowres.reshape(-1)\n",
    "        k = int(round(0.05 * magnitude_vals.shape[0]))\n",
    "        scale = magnitude_vals[magnitude_vals.argsort()[::-1][k]]\n",
    "        kspace = kspace/scale\n",
    "        target = target/scale\n",
    "        # Convert everything from numpy arrays to tensors\n",
    "        kspace_torch = cplx.to_tensor(kspace).float()   \n",
    "        target_torch = cplx.to_tensor(target).float()   \n",
    "        # Use poisson mask instead\n",
    "        mask2 = sp.mri.poisson((256,160), 5, calib=(18, 14), dtype=float, crop_corner=False, return_density=True, seed=0, max_attempts=6, tol=0.01)\n",
    "        mask2[128-10:128+9,80-8:80+7] = 1\n",
    "        mask_torch = torch.stack([torch.tensor(mask2).float(),torch.tensor(mask2).float()],dim=2)\n",
    "        mask_torch = T.kspace_crop(mask_torch,0.67)\n",
    "        #kspace_torch = T.kspace_cut(mask_torch,0.5)\n",
    "        kspace_torch = T.awgn_torch(kspace_torch,15,L=1)\n",
    "        kspace_torch = kspace_torch*mask_torch\n",
    "\n",
    "        ### Reference addition ###\n",
    "        im_lowres_ref = abs(sp.ifft(sp.resize(sp.resize(reference_kspace,(256,24)),(256,160))))\n",
    "        magnitude_vals_ref = im_lowres_ref.reshape(-1)\n",
    "        k_ref = int(round(0.05 * magnitude_vals_ref.shape[0]))\n",
    "        scale_ref = magnitude_vals_ref[magnitude_vals_ref.argsort()[::-1][k_ref]]\n",
    "        reference = reference / scale_ref\n",
    "        reference_torch = cplx.to_tensor(reference).float()\n",
    "        \"\"\"\n",
    "        # Fusion test\n",
    "        fusion_block = ImageFusionBlock()\n",
    "        image = T.ifft2(kspace_torch)\n",
    "        #print(f'image shape: {image.shape}')\n",
    "        real_part = image[:,:, 0]\n",
    "        imag_part = image[:,:, 1]\n",
    "        phase = torch.atan2(imag_part, real_part)\n",
    "        #print(f'phase shape {phase.shape}')\n",
    "        image = fusion_block(kspace_torch, reference_torch)\n",
    "        #print(f'image shape after sim {image.shape}')\n",
    "        real_part = image[:,:,0] * torch.cos(phase)\n",
    "        imag_part = image[:,:,0] * torch.sin(phase)\n",
    "        image = torch.stack((real_part, imag_part), dim=2)\n",
    "        kspace_torch_original = kspace_torch\n",
    "        kspace_torch = T.fft2(image)\n",
    "        \"\"\"\n",
    "        return kspace_torch,target_torch,mask_torch, reference_torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(args):\n",
    "    # Generate k-t undersampling masks\n",
    "    train_mask = MaskFunc([0.08],[4])\n",
    "    train_data = SliceData(\n",
    "        root=str(args.data_path),\n",
    "        transform=DataTransform(train_mask, args),\n",
    "        sample_rate=1\n",
    "    )\n",
    "    return train_data\n",
    "def create_data_loaders(args):\n",
    "    train_data = create_datasets(args)\n",
    "#     print(train_data[0])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    return train_loader\n",
    "def build_optim(args, params):\n",
    "    optimizer = torch.optim.Adam(params, lr=args.lr, weight_decay=args.weight_decay)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameters\n",
    "params = Namespace()\n",
    "#params.data_path = \"./registered_data/patient23b/\"\n",
    "params.data_path = \"./registered_data/\"\n",
    "params.batch_size = 8\n",
    "params.num_grad_steps = 4 #4\n",
    "params.num_cg_steps = 8 #8\n",
    "params.share_weights = True\n",
    "params.modl_lamda = 0.05\n",
    "params.lr = 0.0001\n",
    "#params.lr = 0.0001\n",
    "params.weight_decay = 0\n",
    "params.lr_step_size = 10\n",
    "params.lr_gamma = 0.3\n",
    "params.epoch = 61\n",
    "params.reference_mode = 0\n",
    "params.reference_lambda = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tal/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 5, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_loader = create_data_loaders(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tal/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tal/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#single_MoDL = UnrolledModel(params).to(device)\n",
    "#single_MoDL = MyNetwork(2,2).to(device)\n",
    "single_MoDL = Unrolled(params).to(device)\n",
    "#single_MoDL = UnrolledRef(params).to(device)\n",
    "#single_MoDL = UnrolledTrans(params).to(device)\n",
    "optimizer = build_optim(params, single_MoDL.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, params.lr_step_size, params.lr_gamma)\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch = [  0/ 61] Iter = [   0/  67] Loss = 0.05517 Avg Loss = 0.05517\n",
      "INFO:root:Epoch = [  1/ 61] Iter = [   0/  67] Loss = 0.1284 Avg Loss = 0.1284\n"
     ]
    }
   ],
   "source": [
    "### Load for fine-tunning\n",
    "#checkpoint_file = \"./L2_checkpoints_poisson_x4_SAunrolledOF/model_20.pt\"\n",
    "#checkpoint = torch.load(checkpoint_file,map_location=device)\n",
    "#params = checkpoint[\"params\"]\n",
    "#single_MoDL.load_state_dict(checkpoint['model'])\n",
    "import warnings\n",
    "\n",
    "# Suppress specific deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Function sporco.util.tikhonov_filter is deprecated.*\")\n",
    "\n",
    "# Suppress specific user warnings from torchvision.models\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Using 'weights' as positional parameter.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Arguments other than a weight enum or `None` for 'weights' are deprecated.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, \n",
    "                        message=\".*Function sporco.util.tikhonov_filter is deprecated; please use function sporco.signal.tikhonov_filter instead.*\")\n",
    "\n",
    "epochs_plot = []\n",
    "losses_plot = []\n",
    "\n",
    "for epoch in range(params.epoch):\n",
    "    single_MoDL.train()\n",
    "    avg_loss = 0.\n",
    "    running_loss = 0.0\n",
    "    for iter, data in enumerate(train_loader):\n",
    "        input,target,mask,reference = data\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "        mask = mask.to(device)\n",
    "        reference = reference.to(device)\n",
    "\n",
    "        im_out = single_MoDL(input.float(),reference_image=reference,mask=mask)\n",
    "        loss = criterion(im_out,target)\n",
    "        running_loss = running_loss + loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss = 0.99 * avg_loss + 0.01 * loss.item() if iter > 0 else loss.item()\n",
    "        if iter % 125 == 0:\n",
    "            logging.info(\n",
    "                f'Epoch = [{epoch:3d}/{params.epoch:3d}] '\n",
    "                f'Iter = [{iter:4d}/{len(train_loader):4d}] '\n",
    "                f'Loss = {loss.item():.4g} Avg Loss = {avg_loss:.4g}'\n",
    "            )\n",
    "    #Saving the model\n",
    "    exp_dir = \"L2_checkpoints_poisson_x2_SAunrolledPlug/\"\n",
    "    if epoch % 5 == 0:\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'params': params,\n",
    "                'model': single_MoDL.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'exp_dir': exp_dir\n",
    "            },\n",
    "            f=os.path.join(exp_dir, 'model_%d.pt'%(epoch))\n",
    "    )\n",
    "    running_loss = running_loss / len(train_loader)\n",
    "    #scheduler.step(running_loss)\n",
    "    scheduler.step()\n",
    "    # Append epoch and average loss to plot lists\n",
    "    epochs_plot.append(epoch)\n",
    "    losses_plot.append(running_loss)\n",
    "\n",
    "# Plotting the loss curve\n",
    "plt.figure()\n",
    "plt.plot(epochs_plot, losses_plot, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('SA unrolled with Reference L2 train Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(exp_dir, 'loss_plot_plato_down.png'))  # Save plot as an image\n",
    "\n",
    "# Save all_losses to a file for later comparison\n",
    "losses_file = os.path.join(exp_dir, 'all_losses.txt')\n",
    "with open(losses_file, 'w') as f:\n",
    "    for loss in losses_plot:\n",
    "        f.write(f'{loss}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
